{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e5aa15c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 04:48:14.303022: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-31 04:48:23.504950: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /uscms_data/d3/nswood/mambaforge/lib/:/uscms_data/d3/nswood/mambaforge/lib/python3.9/site-packages/nvidia/cudnn/lib:/uscms_data/d3/nswood/mambaforge/lib/:/uscms_data/d3/nswood/mambaforge/lib/python3.9/site-packages/nvidia/cudnn/lib:/uscms_data/d3/nswood/mambaforge/lib/:/uscms_data/d3/nswood/mambaforge/lib/python3.9/site-packages/nvidia/cudnn/lib:\n",
      "2023-07-31 04:48:23.507017: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /uscms_data/d3/nswood/mambaforge/lib/:/uscms_data/d3/nswood/mambaforge/lib/python3.9/site-packages/nvidia/cudnn/lib:/uscms_data/d3/nswood/mambaforge/lib/:/uscms_data/d3/nswood/mambaforge/lib/python3.9/site-packages/nvidia/cudnn/lib:/uscms_data/d3/nswood/mambaforge/lib/:/uscms_data/d3/nswood/mambaforge/lib/python3.9/site-packages/nvidia/cudnn/lib:\n",
      "2023-07-31 04:48:23.507081: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-07-31 04:48:52.403477: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-31 04:48:53.371281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10823 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:65:00.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from qkeras import *\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from telescope import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c4267ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.random.uniform([2,96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "24fd89c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([96, 1])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(indices, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b98cd37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1  5]\n",
      " [ 1  1]\n",
      " [10  1]], shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor = [[1, 1], [1, 1], [1, 1]]    # tf.rank(tensor) == 2\n",
    "indices = [[0, 1], [2, 0]]           # num_updates == 2, index_depth == 2\n",
    "updates = [5, 10]                    # num_updates == 2\n",
    "print(tf.tensor_scatter_nd_update(tensor, indices, updates))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "42e404f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  9  0 10 11  0  0 12], shape=(8,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor = [0, 0, 0, 0, 0, 0, 0, 0]    # tf.rank(tensor) == 1\n",
    "indices = [[1], [3], [4], [7]]       # num_updates == 4, index_depth == 1\n",
    "updates = [9, 10, 11, 12]            # num_updates == 4\n",
    "print(tf.tensor_scatter_nd_update(tensor, indices, updates))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e2552169",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 96, 1), dtype=int32, numpy=\n",
       "array([[[  0],\n",
       "        [  1],\n",
       "        [  2],\n",
       "        [  3],\n",
       "        [  4],\n",
       "        [  5],\n",
       "        [  6],\n",
       "        [  7],\n",
       "        [  8],\n",
       "        [  9],\n",
       "        [ 12],\n",
       "        [ 13],\n",
       "        [ 16],\n",
       "        [ 17],\n",
       "        [ 18],\n",
       "        [ 19],\n",
       "        [ 20],\n",
       "        [ 21],\n",
       "        [ 22],\n",
       "        [ 23],\n",
       "        [ 24],\n",
       "        [ 25],\n",
       "        [ 28],\n",
       "        [ 29],\n",
       "        [ 32],\n",
       "        [ 33],\n",
       "        [ 34],\n",
       "        [ 35],\n",
       "        [ 36],\n",
       "        [ 37],\n",
       "        [ 38],\n",
       "        [ 39],\n",
       "        [ 40],\n",
       "        [ 41],\n",
       "        [ 44],\n",
       "        [ 45],\n",
       "        [ 48],\n",
       "        [ 49],\n",
       "        [ 50],\n",
       "        [ 51],\n",
       "        [ 52],\n",
       "        [ 53],\n",
       "        [ 54],\n",
       "        [ 55],\n",
       "        [ 56],\n",
       "        [ 57],\n",
       "        [ 60],\n",
       "        [ 61],\n",
       "        [ 64],\n",
       "        [ 65],\n",
       "        [ 66],\n",
       "        [ 67],\n",
       "        [ 68],\n",
       "        [ 69],\n",
       "        [ 70],\n",
       "        [ 71],\n",
       "        [ 72],\n",
       "        [ 73],\n",
       "        [ 76],\n",
       "        [ 77],\n",
       "        [ 80],\n",
       "        [ 81],\n",
       "        [ 82],\n",
       "        [ 83],\n",
       "        [ 84],\n",
       "        [ 85],\n",
       "        [ 86],\n",
       "        [ 87],\n",
       "        [ 88],\n",
       "        [ 89],\n",
       "        [ 92],\n",
       "        [ 93],\n",
       "        [ 96],\n",
       "        [ 97],\n",
       "        [ 98],\n",
       "        [ 99],\n",
       "        [100],\n",
       "        [101],\n",
       "        [102],\n",
       "        [103],\n",
       "        [104],\n",
       "        [105],\n",
       "        [108],\n",
       "        [109],\n",
       "        [112],\n",
       "        [113],\n",
       "        [114],\n",
       "        [115],\n",
       "        [116],\n",
       "        [117],\n",
       "        [118],\n",
       "        [119],\n",
       "        [120],\n",
       "        [121],\n",
       "        [124],\n",
       "        [125]],\n",
       "\n",
       "       [[  0],\n",
       "        [  1],\n",
       "        [  2],\n",
       "        [  3],\n",
       "        [  4],\n",
       "        [  5],\n",
       "        [  6],\n",
       "        [  7],\n",
       "        [  8],\n",
       "        [  9],\n",
       "        [ 12],\n",
       "        [ 13],\n",
       "        [ 16],\n",
       "        [ 17],\n",
       "        [ 18],\n",
       "        [ 19],\n",
       "        [ 20],\n",
       "        [ 21],\n",
       "        [ 22],\n",
       "        [ 23],\n",
       "        [ 24],\n",
       "        [ 25],\n",
       "        [ 28],\n",
       "        [ 29],\n",
       "        [ 32],\n",
       "        [ 33],\n",
       "        [ 34],\n",
       "        [ 35],\n",
       "        [ 36],\n",
       "        [ 37],\n",
       "        [ 38],\n",
       "        [ 39],\n",
       "        [ 40],\n",
       "        [ 41],\n",
       "        [ 44],\n",
       "        [ 45],\n",
       "        [ 48],\n",
       "        [ 49],\n",
       "        [ 50],\n",
       "        [ 51],\n",
       "        [ 52],\n",
       "        [ 53],\n",
       "        [ 54],\n",
       "        [ 55],\n",
       "        [ 56],\n",
       "        [ 57],\n",
       "        [ 60],\n",
       "        [ 61],\n",
       "        [ 64],\n",
       "        [ 65],\n",
       "        [ 66],\n",
       "        [ 67],\n",
       "        [ 68],\n",
       "        [ 69],\n",
       "        [ 70],\n",
       "        [ 71],\n",
       "        [ 72],\n",
       "        [ 73],\n",
       "        [ 76],\n",
       "        [ 77],\n",
       "        [ 80],\n",
       "        [ 81],\n",
       "        [ 82],\n",
       "        [ 83],\n",
       "        [ 84],\n",
       "        [ 85],\n",
       "        [ 86],\n",
       "        [ 87],\n",
       "        [ 88],\n",
       "        [ 89],\n",
       "        [ 92],\n",
       "        [ 93],\n",
       "        [ 96],\n",
       "        [ 97],\n",
       "        [ 98],\n",
       "        [ 99],\n",
       "        [100],\n",
       "        [101],\n",
       "        [102],\n",
       "        [103],\n",
       "        [104],\n",
       "        [105],\n",
       "        [108],\n",
       "        [109],\n",
       "        [112],\n",
       "        [113],\n",
       "        [114],\n",
       "        [115],\n",
       "        [116],\n",
       "        [117],\n",
       "        [118],\n",
       "        [119],\n",
       "        [120],\n",
       "        [121],\n",
       "        [124],\n",
       "        [125]]], dtype=int32)>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " tf.expand_dims(tf.repeat( tf.expand_dims(indices, 0),2,axis=0),axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6fcab78d",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:GPU:0}} Outer dimensions of indices and update must match. Indices shape: [96,1], updates shape:[1,96] [Op:TensorScatterUpdate]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [172], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m indices \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(numbers_list, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Convert 'a' to a TensorFlow constant and reshape it to match the indices shape\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Update the values in 'result_array' at the specified indices with values from 'a_tf'\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m result_array \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor_scatter_nd_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Reshape the 'result_array' into an 8x4x4 tensor\u001b[39;00m\n\u001b[1;32m     14\u001b[0m result_array \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(result_array, (\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/mambaforge/envs/myenv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/mambaforge/envs/myenv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7215\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7214\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7215\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:GPU:0}} Outer dimensions of indices and update must match. Indices shape: [96,1], updates shape:[1,96] [Op:TensorScatterUpdate]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "a = np.random.rand(1,96)\n",
    "# Convert 'numbers_list' to a TensorFlow constant\n",
    "indices = tf.constant(numbers_list, dtype=tf.int32)\n",
    "\n",
    "# Convert 'a' to a TensorFlow constant and reshape it to match the indices shape\n",
    "\n",
    "# Update the values in 'result_array' at the specified indices with values from 'a_tf'\n",
    "result_array = tf.tensor_scatter_nd_update(result_array, tf.expand_dims(indices, 1), a)\n",
    "\n",
    "# Reshape the 'result_array' into an 8x4x4 tensor\n",
    "result_array = tf.reshape(result_array, (8, 4, 4))\n",
    "\n",
    "print(result_array.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "98aba6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 06:38:27.005168: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at scatter_nd_op.cc:216 : INVALID_ARGUMENT: indices[72] = [96] does not index into shape [96]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:GPU:0}} indices[72] = [96] does not index into shape [96] [Op:TensorScatterUpdate]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [156], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m result_array \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mzeros_like(a)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Update the values in 'result_array' at the specified indices with values from 'a_tf'\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m result_array \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor_scatter_nd_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Reshape the 'result_array' into an 8x4x4 tensor\u001b[39;00m\n\u001b[1;32m     15\u001b[0m result_array \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(result_array, (\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/mambaforge/envs/myenv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/mambaforge/envs/myenv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7215\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7214\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7215\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:GPU:0}} indices[72] = [96] does not index into shape [96] [Op:TensorScatterUpdate]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 130, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 280, 290, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 440, 450, 480, 490, 500, 510, 520, 530, 540, 550, 560, 570, 600, 610, 640, 650, 660, 670, 680, 690, 700, 710, 720, 730, 760, 770, 800, 810, 820, 830, 840, 850, 860, 870, 880, 890, 920, 930, 960, 970, 980, 990, 1000, 1010, 1020, 1030, 1040, 1050, 1080, 1090, 1120, 1130, 1140, 1150, 1160, 1170, 1180, 1190, 1200, 1210, 1240, 1250])\n",
    "\n",
    "# Convert 'numbers_list' to a TensorFlow constant\n",
    "indices = tf.constant(numbers_list, dtype=tf.int32)\n",
    "\n",
    "# Convert 'a' to a TensorFlow constant and reshape it to match the indices shape\n",
    "result_array = tf.zeros_like(a)\n",
    "# Update the values in 'result_array' at the specified indices with values from 'a_tf'\n",
    "result_array = tf.tensor_scatter_nd_update(result_array, tf.expand_dims(indices, 1), a)\n",
    "\n",
    "# Reshape the 'result_array' into an 8x4x4 tensor\n",
    "result_array = tf.reshape(result_array, (8, 4, 4))\n",
    "\n",
    "print(result_array.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1c86bf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 93, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 108, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 125]\n"
     ]
    }
   ],
   "source": [
    "numbers_list = [\n",
    "    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, \n",
    "    25, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 48, 49, 50, 51, \n",
    "    52, 53, 54, 55, 56, 57, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, \n",
    "    77, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 93, 96, 97, 98, 99, 100, 101, \n",
    "    102, 103, 104, 105, 108, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 125\n",
    "]\n",
    "\n",
    "print(numbers_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7a6bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_mse_loss(y_true, y_pred):\n",
    "    # Calculate the squared difference between predicted and target values\n",
    "    squared_diff = tf.square(y_pred - y_true)\n",
    "\n",
    "    # Calculate the MSE per row (reduce_mean along axis=1)\n",
    "    mse_per_row = tf.reduce_mean(squared_diff, axis=1)\n",
    "\n",
    "    # Take the mean of the MSE values to get the overall MSE loss\n",
    "    mean_mse_loss = tf.reduce_mean(mse_per_row)\n",
    "\n",
    "    return mean_mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3a0b5ce8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 9, 9, 1)\n",
      "Model: \"cae\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_52 (InputLayer)          [(2000, 9, 9, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " input_53 (InputLayer)          [(2000, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_54 (InputLayer)          [(2000, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " encoder (Functional)           (2000, 18)           2144        ['input_52[0][0]',               \n",
      "                                                                  'input_53[0][0]',               \n",
      "                                                                  'input_54[0][0]']               \n",
      "                                                                                                  \n",
      " decoder (Functional)           (2000, 9, 9, 1)      2505        ['encoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,649\n",
      "Trainable params: 4,649\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch = 2000\n",
    "\n",
    "#Specs\n",
    "n_kernels = 8\n",
    "n_encoded=16\n",
    "conv_weightBits  = 6 \n",
    "conv_biasBits  = 6 \n",
    "dense_weightBits  = 6 \n",
    "dense_biasBits  = 6 \n",
    "encodedBits = 9\n",
    "CNN_kernel_size = 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_enc = Input(batch_shape=(batch,9,9, 1))\n",
    "sum_input = Input(batch_shape=(batch,1))\n",
    "eta = Input(batch_shape =(batch,1))\n",
    "x = QConv2D(n_kernels,\n",
    "            CNN_kernel_size, \n",
    "#             padding='same',\n",
    "            strides=2,\n",
    "            kernel_quantizer=quantized_bits(bits=conv_weightBits,integer=0,keep_negative=1,alpha=1),\n",
    "            bias_quantizer=quantized_bits(bits=conv_biasBits,integer=0,keep_negative=1,alpha=1),\n",
    "            name=\"conv2d\")(input_enc)\n",
    "x = QActivation(\"quantized_relu(bits=8,integer=1)\", name=\"act\")(x)\n",
    "x = Flatten()(x)\n",
    "# x = Concatenate(axis=1)([x[:,:80],x[:,96:112]]) \n",
    "x = QDense(n_encoded, \n",
    "           kernel_quantizer=quantized_bits(bits=dense_weightBits,integer=0,keep_negative=1,alpha=1),\n",
    "           bias_quantizer=quantized_bits(bits=dense_biasBits,integer=0,keep_negative=1,alpha=1),\n",
    "           name=\"dense\")(x)\n",
    "\n",
    "x = concatenate([x,sum_input,eta],axis=1)\n",
    "latent = x\n",
    "\n",
    "input_dec = Input(batch_shape=(batch,18))\n",
    "y = Dense(128)(input_dec)\n",
    "y = ReLU()(y)\n",
    "y = Reshape((4, 4, 8))(y)\n",
    "y = Conv2DTranspose(1, (3, 3), strides=(2, 2))(y)\n",
    "y = ReLU()(y)\n",
    "recon = y\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "encoder = keras.Model([input_enc,sum_input,eta], latent, name=\"encoder\")\n",
    "decoder = keras.Model([input_dec], recon, name=\"decoder\")\n",
    "\n",
    "cae = Model(\n",
    "    inputs=[input_enc,sum_input,eta],\n",
    "    outputs=decoder([encoder([input_enc,sum_input,eta])]),\n",
    "    name=\"cae\"\n",
    ")\n",
    "\n",
    "cae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 1e-5), loss=mean_mse_loss)\n",
    "cae.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4deea2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(nfiles,batchsize):\n",
    "    data_list = []\n",
    "\n",
    "    for i in range(nfiles):\n",
    "        if i == 0:\n",
    "            dt = pd.read_csv('../ECON_AE_Development/AE_Data/1.csv').values\n",
    "        else:\n",
    "            dt_i = pd.read_csv(f'../ECON_AE_Development/AE_Data/{i+1}.csv').values\n",
    "            dt = np.vstack([dt, dt_i])\n",
    "\n",
    "        data_list.append(dt)\n",
    "\n",
    "    data_tensor = tf.convert_to_tensor(np.concatenate(data_list), dtype=tf.float32)\n",
    "\n",
    "    train_size = int(0.8 * len(data_tensor))\n",
    "    test_size = len(data_tensor) - train_size\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    train_data, test_data = tf.split(data_tensor, [train_size, test_size], axis=0)\n",
    "\n",
    "    # Extract specific tensors\n",
    "    train_wafers = expand_tensor(train_data[:, 0:48])\n",
    "    train_sum_calcq = tf.expand_dims(tf.reduce_sum(train_data[:, 0:48], axis=1), axis=1)\n",
    "    train_eta = tf.expand_dims(train_data[:, -2], axis=1)\n",
    "\n",
    "    test_wafers = expand_tensor(test_data[:, 0:48])\n",
    "    test_sum_calcq = tf.expand_dims(tf.reduce_sum(test_data[:, 0:48], axis=1), axis=1)\n",
    "    test_eta = tf.expand_dims(test_data[:, -2], axis=1)\n",
    "\n",
    "    # Create data loaders for training and test data\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_wafers, train_sum_calcq, train_eta))\n",
    "    train_loader = train_dataset.batch(batchsize).shuffle(buffer_size=train_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_wafers, test_sum_calcq, test_eta))\n",
    "    test_loader = test_dataset.batch(batchsize).shuffle(buffer_size=test_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "408176bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_tensor(input_tensor):\n",
    "    arrange = np.array([28,29,30,31,0,4,8,12,\n",
    "                         24,25,26,27,1,5,9,13,\n",
    "                         20,21,22,23,2,6,10,14,\n",
    "                         16,17,18,19,3,7,11,15,\n",
    "                         47,43,39,35,35,34,33,32,\n",
    "                         46,42,38,34,39,38,37,36,\n",
    "                         45,41,37,33,43,42,41,40,\n",
    "                             44,40,36,32,47,46,45,44])\n",
    "    arrMask = np.array([1,1,1,1,1,1,1,1,\n",
    "                        1,1,1,1,1,1,1,1,\n",
    "                        1,1,1,1,1,1,1,1,\n",
    "                        1,1,1,1,1,1,1,1,\n",
    "                        1,1,1,1,0,0,0,0,\n",
    "                        1,1,1,1,0,0,0,0,\n",
    "                        1,1,1,1,0,0,0,0,\n",
    "                        1,1,1,1,0,0,0,0,])\n",
    "   \n",
    "    inputdata = tf.reshape(tf.gather(input_tensor, arrange,axis =1), (input_tensor.shape[0],8, 8, 1))\n",
    "#     inputdata *= tf.cast(tf.reshape(arrMask, (1, 8, 8)), dtype=inputdata.dtype)\n",
    "\n",
    "    paddings = [(0, 0), (0, 1), (0, 1), (0, 0)]\n",
    "    padded_tensor = tf.pad(inputdata, paddings, mode='CONSTANT', constant_values=0)\n",
    "\n",
    "    return padded_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c923ec50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2764000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)*batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f5face9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader = load_data(1,batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e58e8037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 06:55:12.750201: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape ingradient_tape/cae/encoder/act/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.16153756910122596\n",
      "Epoch 2/100, Loss: 0.03399047360233909\n",
      "Epoch 3/100, Loss: 0.3102665162390117\n",
      "Epoch 4/100, Loss: 0.31919509405613633\n",
      "Epoch 5/100, Loss: 0.10831190894136553\n",
      "Epoch 6/100, Loss: 0.215050784333915\n",
      "Epoch 7/100, Loss: 0.4186238573180611\n",
      "Epoch 8/100, Loss: 0.38946575976936243\n",
      "Epoch 9/100, Loss: 0.21934110993276285\n",
      "Epoch 10/100, Loss: 0.2045010686162239\n",
      "Epoch 11/100, Loss: 0.5185253537939875\n",
      "Epoch 12/100, Loss: 0.33309028568488647\n",
      "Epoch 13/100, Loss: 0.20360406418509144\n",
      "Epoch 14/100, Loss: 0.40674306669663074\n",
      "Epoch 15/100, Loss: 0.08346010239182954\n",
      "Epoch 16/100, Loss: 0.39887865645978626\n",
      "Epoch 17/100, Loss: 0.0897992967172228\n",
      "Epoch 18/100, Loss: 0.2778018697429497\n",
      "Epoch 19/100, Loss: 0.16108096089549417\n",
      "Epoch 20/100, Loss: 0.4275206747910738\n",
      "Epoch 21/100, Loss: 0.3976863715196656\n",
      "Epoch 22/100, Loss: 0.3710293976470461\n",
      "Epoch 23/100, Loss: 0.190703836228499\n",
      "Epoch 24/100, Loss: 0.32062857378616\n",
      "Epoch 25/100, Loss: 0.10131027782015103\n",
      "Epoch 26/100, Loss: 0.3086507252142502\n",
      "Epoch 27/100, Loss: 0.39097111294411024\n",
      "Epoch 28/100, Loss: 0.48096381065710925\n",
      "Epoch 29/100, Loss: 0.3881901283698903\n",
      "Epoch 30/100, Loss: 0.3464284343664277\n",
      "Epoch 31/100, Loss: 0.39483061913298456\n",
      "Epoch 32/100, Loss: 0.1872551101416824\n",
      "Epoch 33/100, Loss: 0.3229593196998629\n",
      "Epoch 34/100, Loss: 0.43042458915434423\n",
      "Epoch 35/100, Loss: 0.48923492869764956\n",
      "Epoch 36/100, Loss: 0.4019786508687153\n",
      "Epoch 37/100, Loss: 0.22403023986015927\n",
      "Epoch 38/100, Loss: 0.2569925267396201\n",
      "Epoch 39/100, Loss: 0.4435992751376846\n",
      "Epoch 40/100, Loss: 0.09345974799762069\n",
      "Epoch 41/100, Loss: 0.44940924476921645\n",
      "Epoch 42/100, Loss: 0.010354538905120276\n",
      "Epoch 43/100, Loss: 0.0653617578235963\n",
      "Epoch 44/100, Loss: 0.35785143274439746\n",
      "Epoch 45/100, Loss: 0.017491485490812753\n",
      "Epoch 46/100, Loss: 0.03191735290411412\n",
      "Epoch 47/100, Loss: 0.3152453801697484\n",
      "Epoch 48/100, Loss: 0.3676476649603174\n",
      "Epoch 49/100, Loss: 0.15576038361975839\n",
      "Epoch 50/100, Loss: 0.18188863951217937\n",
      "Epoch 51/100, Loss: 0.09938353202035907\n",
      "Epoch 52/100, Loss: 0.3898531097468695\n",
      "Epoch 53/100, Loss: 0.3608887283971099\n",
      "Epoch 54/100, Loss: 0.10213305243810938\n",
      "Epoch 55/100, Loss: 0.44192098144373915\n",
      "Epoch 56/100, Loss: 0.3339736360337386\n",
      "Epoch 57/100, Loss: 0.0027391997473974823\n",
      "Epoch 58/100, Loss: 0.202459391987272\n",
      "Epoch 59/100, Loss: 0.22614809628333438\n",
      "Epoch 60/100, Loss: 0.2552547580716234\n",
      "Epoch 61/100, Loss: 0.02426496208179877\n",
      "Epoch 62/100, Loss: 0.08903045625866063\n",
      "Epoch 63/100, Loss: 0.36613934535676596\n",
      "Epoch 64/100, Loss: 0.20720527148764317\n",
      "Epoch 65/100, Loss: 0.21689754304181993\n",
      "Epoch 66/100, Loss: 0.3286371134862886\n",
      "Epoch 67/100, Loss: 0.48515911650968185\n",
      "Epoch 68/100, Loss: 0.42475148080226827\n",
      "Epoch 69/100, Loss: 0.008465491584689504\n",
      "Epoch 70/100, Loss: 0.44983878889718726\n",
      "Epoch 71/100, Loss: 0.05365524741226616\n",
      "Epoch 72/100, Loss: 0.23266501087252206\n",
      "Epoch 73/100, Loss: 0.23652428050945187\n",
      "Epoch 74/100, Loss: 0.33905875447655554\n",
      "Epoch 75/100, Loss: 0.04623727867054698\n",
      "Epoch 76/100, Loss: 0.2594953586106363\n",
      "Epoch 77/100, Loss: 0.37971619420251695\n",
      "Epoch 78/100, Loss: 0.0624587369855337\n",
      "Epoch 79/100, Loss: 0.26977165204364206\n",
      "Epoch 80/100, Loss: 0.37142514077419825\n",
      "Epoch 81/100, Loss: 0.18573382743360684\n",
      "Epoch 82/100, Loss: 0.026729513071725407\n",
      "Epoch 83/100, Loss: 0.20565629086170115\n",
      "Epoch 84/100, Loss: 0.3846926247248946\n",
      "Epoch 85/100, Loss: 0.397161377145654\n",
      "Epoch 86/100, Loss: 0.3968105822989634\n",
      "Epoch 87/100, Loss: 0.2793611290499719\n",
      "Epoch 88/100, Loss: 0.2470885760063028\n",
      "Epoch 89/100, Loss: 0.3991915265316556\n",
      "Epoch 90/100, Loss: 0.296276657780069\n",
      "Epoch 91/100, Loss: 0.20425152897524246\n",
      "Epoch 92/100, Loss: 0.3693019611673314\n",
      "Epoch 93/100, Loss: 0.3671458788849683\n",
      "Epoch 94/100, Loss: 0.09972330746878419\n",
      "Epoch 95/100, Loss: 0.3733063869724743\n",
      "Epoch 96/100, Loss: 0.26376380119654963\n",
      "Epoch 97/100, Loss: 0.13262333261500908\n",
      "Epoch 98/100, Loss: 0.2838193013402384\n",
      "Epoch 99/100, Loss: 0.3773120389426324\n",
      "Epoch 100/100, Loss: 0.2551056790317364\n"
     ]
    }
   ],
   "source": [
    "nepochs = 100\n",
    "for epoch in range(nepochs):\n",
    "    total_loss = 0\n",
    "    for wafers, sum_calcq, eta in train_loader:\n",
    "        # Train the CAE model on each batch\n",
    "        tensor2_expanded = tf.expand_dims(tf.expand_dims(sum_calcq, -1), -1)\n",
    "\n",
    "        if wafers.shape[0] != batch:\n",
    "            break\n",
    "        loss = cae.train_on_batch([wafers, sum_calcq, eta], wafers)\n",
    "        total_loss += loss\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}/{nepochs}, Loss: {total_loss/(len(train_loader)*batch)}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcc587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(args):\n",
    "    data_list = []\n",
    "\n",
    "    for i in range(args.nfiles):\n",
    "        if i == 0:\n",
    "            dt = pd.read_csv('../ECON_AE_Development/AE_Data/1.csv').values\n",
    "        else:\n",
    "            dt_i = pd.read_csv(f'../ECON_AE_Development/AE_Data/{i+1}.csv').values\n",
    "            dt = np.vstack([dt, dt_i])\n",
    "\n",
    "        data_list.append(dt)\n",
    "\n",
    "    data_tensor = tf.convert_to_tensor(np.concatenate(data_list), dtype=tf.float32)\n",
    "\n",
    "    train_size = int(0.8 * len(data_tensor))\n",
    "    test_size = len(data_tensor) - train_size\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    train_data, test_data = tf.split(data_tensor, [train_size, test_size], axis=0)\n",
    "\n",
    "    # Extract specific tensors\n",
    "    train_wafers = train_data[:, 0:48]\n",
    "    train_sum_calcq = tf.reduce_sum(train_data[:, 0:48], axis=1)\n",
    "    train_eta = train_data[:, -2]\n",
    "\n",
    "    test_wafers = test_data[:, 0:48]\n",
    "    test_sum_calcq = tf.reduce_sum(test_data[:, 0:48], axis=1)\n",
    "    test_eta = test_data[:, -2]\n",
    "\n",
    "    # Create data loaders for training and test data\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_wafers, train_sum_calcq, train_eta))\n",
    "    train_loader = train_dataset.batch(args.batchsize).shuffle(buffer_size=train_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_wafers, test_sum_calcq, test_eta))\n",
    "    test_loader = test_dataset.batch(args.batchsize).shuffle(buffer_size=test_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_loader, test_loader\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
